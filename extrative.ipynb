{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8df021dc9e504da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:14.998341Z",
     "start_time": "2024-08-03T07:32:14.989455Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install sacrebleu --quiet\n",
    "# !pip install sentence-transformers --quiet\n",
    "# !pip install rouge-score --quiet\n",
    "# !pip install streamlit --quiet\n",
    "# !pip install flask --quiet\n",
    "# !pip install tf-keras --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69d40161cf8d9ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.072901Z",
     "start_time": "2024-08-03T07:32:15.067684Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from string import punctuation\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from rouge_score import rouge_scorer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4769ac4c768e0ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.086584Z",
     "start_time": "2024-08-03T07:32:15.084080Z"
    }
   },
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "Pennsylvania Gov. Josh Shapiro said former President Donald Trump has left the Butler, Pennsylvania, area following the rally shooting Saturday.\n",
    "\n",
    "“Under the protection of US Secret Service and with the assistance of the Pennsylvania State Police, former President Trump has now left the Butler area,” Shapiro said in a statement posted to X. “Lori and I are thankful that his team reports that he is fine and we continue to wish him a full and speedy recovery.”\n",
    "\n",
    "“We mourn the loss of life and pray for the two victims who are being treated at this time,” he added. “I am grateful for all law enforcement who responded, protected the former president, and worked to bring the situation under control.”\n",
    "\n",
    "Federal law enforcement officials will continue to lead on the investigation into the shooting, Shapiro said. Meanwhile, Pennsylvania State Police will lead the investigation into the shooting of the other victims. Shapiro said he has been communicating with law enforcement on the ground in Pennsylvania and has spoken with President Joe Biden, who “offered his full support.”\n",
    "\n",
    "Shapiro said he knows “how painful and shocking this event is to so many of our fellow Pennsylvanians.” He asked “that we treat our fellow Americans with respect and join together to universally condemn the unacceptable violence we witnessed earlier today in Butler.”\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd4831528cd6fe8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.090621Z",
     "start_time": "2024-08-03T07:32:15.088870Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt_summary = '''Pennsylvania Governor Josh Shapiro announced that former President Donald Trump has safely left the Butler area following a rally shooting. Shapiro expressed gratitude for Trump’s protection by the Secret Service and Pennsylvania State Police and mourned the loss of two victims. He noted that federal and state authorities are investigating the incident and emphasized the need for respect and condemnation of the violence.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aeeacfdf740ca276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.113669Z",
     "start_time": "2024-08-03T07:32:15.109712Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english') + list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "458d65991aa9e4d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.122559Z",
     "start_time": "2024-08-03T07:32:15.120755Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "\n",
    "    # remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # remove \\n and quotes like “, ‘, ”\n",
    "    text = re.sub(r'[\\n“”‘’]', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24266c9d50ff2112",
   "metadata": {},
   "source": [
    "### Extractive text summarization using word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.130637Z",
     "start_time": "2024-08-03T07:32:15.127395Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    text = clean_text(text)\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Tokenize the text into words and filter out stopwords and punctuation\n",
    "    words = word_tokenize(text.lower())\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Calculate word frequencies\n",
    "    word_frequencies = {}\n",
    "    for word in filtered_words:\n",
    "        if word not in word_frequencies:\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n",
    "\n",
    "    # Calculate sentence scores\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in word_frequencies:\n",
    "                if sentence not in sentence_scores:\n",
    "                    sentence_scores[sentence] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sentence] += word_frequencies[word]\n",
    "\n",
    "    # Get the top 30% of sentences with the highest scores\n",
    "    summary_sentences = heapq.nlargest(int(len(sentences) * 0.3), sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a611c100dbca42b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.136983Z",
     "start_time": "2024-08-03T07:32:15.132892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Under the protection of US Secret Service and with the assistance of the Pennsylvania State Police, former President Trump has now left the Butler area, Shapiro said in a statement posted to X. Lori and I are thankful that his team reports that he is fine and we continue to wish him a full and speedy recovery. Josh Shapiro said former President Donald Trump has left the Butler, Pennsylvania, area following the rally shooting Saturday. Shapiro said he has been communicating with law enforcement on the ground in Pennsylvania and has spoken with President Joe Biden, who offered his full support.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_summary = summarize_text(paragraph)\n",
    "freq_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8592a2e709ca660",
   "metadata": {},
   "source": [
    "### Extractive text summarization using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e93a90681109374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.156175Z",
     "start_time": "2024-08-03T07:32:15.152855Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_tfidf_scores(text):\n",
    "    vectorizer = TfidfVectorizer(stop_words=list(stop_words))\n",
    "    vectors = vectorizer.fit_transform([text])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    # dense =\n",
    "    dense_list = vectors.todense().tolist()\n",
    "    tfidf_scores = dict(zip(feature_names, dense_list[0]))\n",
    "    return tfidf_scores\n",
    "\n",
    "\n",
    "def summarize_text_with_tfidf(text, summary_ratio=0.3):\n",
    "    text = clean_text(text)\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    # Compute TF-IDF scores for words in the text\n",
    "    tfidf_scores = compute_tfidf_scores(text)\n",
    "\n",
    "    # Calculate sentence scores\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        sentence_score = sum(tfidf_scores.get(word, 0) for word in words)\n",
    "        sentence_scores[sentence] = sentence_score / len(words)  # Normalize by sentence length\n",
    "\n",
    "    # Get the top `summary_ratio`% of sentences with the highest scores\n",
    "    num_summary_sentences = max(1, int(len(sentences) * summary_ratio))\n",
    "    summary_sentences = heapq.nlargest(num_summary_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4171474b95e28b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:15.189418Z",
     "start_time": "2024-08-03T07:32:15.165090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pennsylvania Gov. Josh Shapiro said former President Donald Trump has left the Butler, Pennsylvania, area following the rally shooting Saturday. Federal law enforcement officials will continue to lead on the investigation into the shooting, Shapiro said.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_summary = summarize_text_with_tfidf(paragraph)\n",
    "tfidf_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48fbccc2814113",
   "metadata": {},
   "source": [
    "### Extractive text summarization using transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e426f6fb1ffa4f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:16.255568Z",
     "start_time": "2024-08-03T07:32:15.193110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def summarize_text_with_transformer(text, summary_ratio=0.3):\n",
    "    text = clean_text(text)\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    # Compute sentence embeddings\n",
    "    sentence_embeddings = compute_sentence_embeddings(sentences)\n",
    "\n",
    "    # Compute pairwise sentence similarities\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_score = util.pytorch_cos_sim(sentence_embeddings[i], sentence_embeddings).sum().item()\n",
    "        sentence_scores[sentence] = sentence_score / len(sentences)  # Normalize by number of sentences\n",
    "\n",
    "    # Get the top `summary_ratio`% of sentences with the highest scores\n",
    "    num_summary_sentences = max(1, int(len(sentences) * summary_ratio))\n",
    "    summary_sentences = heapq.nlargest(num_summary_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26e59b4737bc4103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:16.445886Z",
     "start_time": "2024-08-03T07:32:16.256455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Under the protection of US Secret Service and with the assistance of the Pennsylvania State Police, former President Trump has now left the Butler area, Shapiro said in a statement posted to X. Lori and I are thankful that his team reports that he is fine and we continue to wish him a full and speedy recovery. Shapiro said he has been communicating with law enforcement on the ground in Pennsylvania and has spoken with President Joe Biden, who offered his full support. Shapiro said he knows how painful and shocking this event is to so many of our fellow Pennsylvanians.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_summary = summarize_text_with_transformer(paragraph)\n",
    "transformer_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339492f96a59a935",
   "metadata": {},
   "source": [
    "### Extractive text summarization using NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f81a2fd020d5699e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:16.792689Z",
     "start_time": "2024-08-03T07:32:16.446662Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def score_with_ner(sentence, nlp_model):\n",
    "    doc = nlp_model(sentence)\n",
    "    return len([ent for ent in doc.ents])\n",
    "\n",
    "\n",
    "def summarize_text_with_ner(text, summary_ratio=0.3):\n",
    "    text = clean_text(text)\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    sentence_embeddings = compute_sentence_embeddings(sentences)\n",
    "    sentence_scores = {}\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        ner_score = score_with_ner(sentence, nlp)\n",
    "        sentence_score = util.pytorch_cos_sim(sentence_embeddings[i], sentence_embeddings).sum().item()\n",
    "        sentence_scores[sentence] = (sentence_score + ner_score) / len(sentences)\n",
    "\n",
    "    num_summary_sentences = max(1, int(len(sentences) * summary_ratio))\n",
    "    summary_sentences = heapq.nlargest(num_summary_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "38f8e30b807115a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:16.905790Z",
     "start_time": "2024-08-03T07:32:16.794450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Under the protection of US Secret Service and with the assistance of the Pennsylvania State Police, former President Trump has now left the Butler area, Shapiro said in a statement posted to X. Lori and I are thankful that his team reports that he is fine and we continue to wish him a full and speedy recovery. Josh Shapiro said former President Donald Trump has left the Butler, Pennsylvania, area following the rally shooting Saturday. Shapiro said he has been communicating with law enforcement on the ground in Pennsylvania and has spoken with President Joe Biden, who offered his full support.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_summary = summarize_text_with_ner(paragraph)\n",
    "ner_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dedcbd727c25e08",
   "metadata": {},
   "source": [
    "### Extractive text summarization using TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68e9256d2f32864c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:16.909364Z",
     "start_time": "2024-08-03T07:32:16.906466Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_text_with_textrank(text, summary_ratio=0.3):\n",
    "    text = clean_text(text)\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    # Compute sentence embeddings\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "\n",
    "    # Build the similarity graph\n",
    "    similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "\n",
    "    # Apply PageRank algorithm\n",
    "    scores = nx.pagerank(similarity_graph)\n",
    "\n",
    "    # Rank sentences by their scores\n",
    "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "    # Select the top `summary_ratio`% sentences\n",
    "    num_summary_sentences = max(1, int(len(sentences) * summary_ratio))\n",
    "    summary_sentences = [s for score, s in ranked_sentences[:num_summary_sentences]]\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fcc1e41a2bf9e733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:16.942987Z",
     "start_time": "2024-08-03T07:32:16.910005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Under the protection of US Secret Service and with the assistance of the Pennsylvania State Police, former President Trump has now left the Butler area, Shapiro said in a statement posted to X. Lori and I are thankful that his team reports that he is fine and we continue to wish him a full and speedy recovery. Shapiro said he knows how painful and shocking this event is to so many of our fellow Pennsylvanians. Shapiro said he has been communicating with law enforcement on the ground in Pennsylvania and has spoken with President Joe Biden, who offered his full support.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank_summary = summarize_text_with_textrank(paragraph)\n",
    "textrank_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e55db8d33938b",
   "metadata": {},
   "source": [
    "### Extractive text summarization using redundancy removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f01902bef5de17d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:16.947133Z",
     "start_time": "2024-08-03T07:32:16.943623Z"
    }
   },
   "outputs": [],
   "source": [
    "def redundancy_removal(selected_sentences, new_sentence, model, threshold=0.7):\n",
    "    new_embedding = model.encode([new_sentence])[0]\n",
    "    for sent in selected_sentences:\n",
    "        sent_embedding = model.encode([sent])[0]\n",
    "        if cosine_similarity([new_embedding], [sent_embedding])[0][0] > threshold:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def summarize_text_with_redundancy_removal(text, summary_ratio=0.3, redundancy_threshold=0.7):\n",
    "    text = clean_text(text)\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "    similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(similarity_graph)\n",
    "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "    num_summary_sentences = max(1, int(len(sentences) * summary_ratio))\n",
    "    summary_sentences = []\n",
    "    for score, sentence in ranked_sentences:\n",
    "        if len(summary_sentences) < num_summary_sentences and redundancy_removal(summary_sentences, sentence, model,\n",
    "                                                                                 redundancy_threshold):\n",
    "            summary_sentences.append(sentence)\n",
    "\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b86c5d3add247c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:17.033858Z",
     "start_time": "2024-08-03T07:32:16.947785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Under the protection of US Secret Service and with the assistance of the Pennsylvania State Police, former President Trump has now left the Butler area, Shapiro said in a statement posted to X. Lori and I are thankful that his team reports that he is fine and we continue to wish him a full and speedy recovery. Shapiro said he knows how painful and shocking this event is to so many of our fellow Pennsylvanians. Shapiro said he has been communicating with law enforcement on the ground in Pennsylvania and has spoken with President Joe Biden, who offered his full support.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundancy_removal_summary = summarize_text_with_redundancy_removal(paragraph)\n",
    "redundancy_removal_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc838972d4742ba5",
   "metadata": {},
   "source": [
    "### Extractive text summarization using Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c8b4603f97afae4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:22.250744Z",
     "start_time": "2024-08-03T07:32:20.382298Z"
    }
   },
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "\n",
    "def summarize_text_with_bert(text, summary_ratio=0.3):\n",
    "    max_length = int(len(text.split()) * summary_ratio)\n",
    "    min_length = max(5, int(max_length * 0.3))\n",
    "    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "    return summary[0]['summary_text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d64ea16730bf5431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:26.170390Z",
     "start_time": "2024-08-03T07:32:22.252156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gov. Josh Shapiro says former President Trump has left the Butler, Pennsylvania, area following the shooting . Shapiro: \"Under the protection of US Secret Service and with the assistance of the Pennsylvania State Police, the former president has now left the area . Shapiro said he has been communicating with law enforcement on the ground in'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_summary = summarize_text_with_bert(paragraph)\n",
    "bert_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fbbdfd5ca2a92",
   "metadata": {},
   "source": [
    "### Evaluation of the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42719ae20aba9438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:26.174564Z",
     "start_time": "2024-08-03T07:32:26.171311Z"
    }
   },
   "outputs": [],
   "source": [
    "def rouge_evaluate_summary(reference, summary) -> float:\n",
    "    _scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    return _scorer.score(reference, summary)\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "\n",
    "def blue_evaluate_summary(reference, summary):\n",
    "    return sentence_bleu(reference, summary)\n",
    "    # return sacrebleu.corpus_bleu(summary, [reference])\n",
    "\n",
    "\n",
    "def evaluate_all_summaries(reference, summaries):\n",
    "    evaluation_results = []\n",
    "    for method, summary in summaries.items():\n",
    "        _rouge_scores = rouge_evaluate_summary(reference, summary)\n",
    "\n",
    "        evaluation_results.append({\n",
    "            'method': method,\n",
    "            'rouge1': round(_rouge_scores['rouge1'].fmeasure, 4),\n",
    "            'rouge2': round(_rouge_scores['rouge2'].fmeasure, 4),\n",
    "            'rougeL': round(_rouge_scores['rougeL'].fmeasure, 4),\n",
    "        })\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f587486a2c1f2d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:26.178233Z",
     "start_time": "2024-08-03T07:32:26.175627Z"
    }
   },
   "outputs": [],
   "source": [
    "all_summaries = {\n",
    "    'Frequency Summary': freq_summary,\n",
    "    'Tfidf Summary': tfidf_summary,\n",
    "    'Transformer Summary': transformer_summary,\n",
    "    'Ner Summary': ner_summary,\n",
    "    'Textrank Summary': textrank_summary,\n",
    "    'Redundancy Removal Summary': redundancy_removal_summary,\n",
    "    'Bert Summary': bert_summary,\n",
    "}\n",
    "\n",
    "all_summaries_functions = {\n",
    "    'Frequency Summary': summarize_text,\n",
    "    'Tfidf Summary': summarize_text_with_tfidf,\n",
    "    'Transformer Summary': summarize_text_with_transformer,\n",
    "    'Ner Summary': summarize_text_with_ner,\n",
    "    'Textrank Summary': summarize_text_with_textrank,\n",
    "    'Redundancy Removal Summary': summarize_text_with_redundancy_removal,\n",
    "    'Bert Summary': summarize_text_with_bert,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "37da6cd16c7a7410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:26.717679Z",
     "start_time": "2024-08-03T07:32:26.179079Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/mac/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/mac/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores_rouge = evaluate_all_summaries(paragraph, all_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9128feb3e3104a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:26.730077Z",
     "start_time": "2024-08-03T07:32:26.718379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frequency Summary</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.5563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tfidf Summary</td>\n",
       "      <td>0.2824</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.2824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformer Summary</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ner Summary</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.5563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Textrank Summary</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Redundancy Removal Summary</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6164</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bert Summary</td>\n",
       "      <td>0.3883</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       method  rouge1  rouge2  rougeL  bleu\n",
       "0           Frequency Summary  0.6312  0.6164  0.5563   0.0\n",
       "1               Tfidf Summary  0.2824  0.2688  0.2824   0.0\n",
       "2         Transformer Summary  0.6312  0.6226  0.6312   0.0\n",
       "3                 Ner Summary  0.6312  0.6164  0.5563   0.0\n",
       "4            Textrank Summary  0.6312  0.6164  0.5437   0.0\n",
       "5  Redundancy Removal Summary  0.6312  0.6164  0.5437   0.0\n",
       "6                Bert Summary  0.3883  0.3469  0.3736   0.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(scores_rouge)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72befa7bd2f0e82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:32:26.733746Z",
     "start_time": "2024-08-03T07:32:26.730776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best method based on rougeL: Transformer Summary\n"
     ]
    }
   ],
   "source": [
    "def get_best_method(metric):\n",
    "    # Find the best method based on the chosen metric\n",
    "    _best_method_name = df.loc[df[metric].idxmax(), 'method']\n",
    "\n",
    "    # Retrieve the corresponding summary function\n",
    "    _best_summary_func = all_summaries_functions.get(_best_method_name)\n",
    "\n",
    "    return _best_method_name, _best_summary_func\n",
    "\n",
    "\n",
    "chosen_metric = 'rougeL'\n",
    "best_extractive_method_name, best_extractive_summary_func = get_best_method(chosen_metric)\n",
    "\n",
    "print(f\"Best method based on {chosen_metric}: {best_extractive_method_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d40f03ac1614c632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:46:33.721728Z",
     "start_time": "2024-08-03T07:46:33.719002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer Summary'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_extractive_method_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5349e89e9ec0b4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T03:17:01.190649Z",
     "start_time": "2024-08-15T03:17:01.135979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from flask import Flask, request, jsonify\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import heapq\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "\n",
    "    # remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # remove \\n and quotes like “, ‘, ”\n",
    "    text = re.sub(r'[\\n“”‘’]', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def summarize_text_with_transformer(text, summary_ratio=0.3):\n",
    "    text = clean_text(text)\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    # Compute sentence embeddings\n",
    "    sentence_embeddings = compute_sentence_embeddings(sentences)\n",
    "\n",
    "    # Compute pairwise sentence similarities\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_score = util.pytorch_cos_sim(sentence_embeddings[i], sentence_embeddings).sum().item()\n",
    "        sentence_scores[sentence] = sentence_score / len(sentences)  # Normalize by number of sentences\n",
    "\n",
    "    # Get the top `summary_ratio`% of sentences with the highest scores\n",
    "    num_summary_sentences = max(1, int(len(sentences) * summary_ratio))\n",
    "    summary_sentences = heapq.nlargest(num_summary_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    return \"<p>Hello, World!</p>\"\n",
    "\n",
    "\n",
    "@app.route('/process', methods=['POST'])\n",
    "def process_text():\n",
    "    data = request.json\n",
    "    text = data.get('paragraph')\n",
    "\n",
    "    if not text:\n",
    "        return jsonify({'error': 'Missing text or metric'}), 400\n",
    "\n",
    "    if not summarize_text_with_transformer:\n",
    "        return jsonify({'error': 'Invalid metric'}), 400\n",
    "\n",
    "    summary = summarize_text_with_transformer(text)\n",
    "    return jsonify({\n",
    "        'summary': summary,\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca16b74176654a13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T07:51:10.662948Z",
     "start_time": "2024-08-03T07:51:10.658560Z"
    }
   },
   "outputs": [],
   "source": [
    "# !flask --app main run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2d6f217a37d9675e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T08:33:11.618065Z",
     "start_time": "2024-08-03T08:33:11.611280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import requests\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "import re\n",
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    pdf_reader = PyPDF2.PdfReader(BytesIO(pdf_file.read()))\n",
    "    c = 0\n",
    "    text = \"\"\n",
    "\n",
    "    while c < len(pdf_reader.pages):\n",
    "        pageObj = pdf_reader.pages[c]\n",
    "        # text += pageObj.extract_text()\n",
    "        page_text = pageObj.extract_text()\n",
    "        if page_text:\n",
    "            # Add line breaks based on common patterns\n",
    "            page_text = re.sub(r'\\n+', '\\n', page_text)\n",
    "            text += page_text + \"\\n\"\n",
    "        c += 1\n",
    "\n",
    "    return text.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "# Title of the app\n",
    "st.title(\"Text Summarization App\")\n",
    "\n",
    "# Option to upload PDF or enter text\n",
    "option = st.radio(\"Choose input method\", [\"Upload PDF\", \"Enter Text\"])\n",
    "\n",
    "# Handle PDF upload\n",
    "if option == \"Upload PDF\":\n",
    "    uploaded_file = st.file_uploader(\"Choose a PDF file\", type=\"pdf\")\n",
    "    if uploaded_file is not None:\n",
    "        # Extract text from PDF\n",
    "        pdf_text = extract_text_from_pdf(uploaded_file)\n",
    "        st.text_area(\"Extracted Text\", pdf_text, height=130, )\n",
    "        text_to_process = pdf_text\n",
    "    else:\n",
    "        text_to_process = \"\"\n",
    "\n",
    "# Handle direct text input\n",
    "elif option == \"Enter Text\":\n",
    "    text_to_process = st.text_area(\"Enter your paragraph to summarize here:\", height=100)\n",
    "\n",
    "# Button to process the text\n",
    "if st.button(\"Summarize Text\"):\n",
    "    if text_to_process:\n",
    "        response = requests.post(\n",
    "            'http://127.0.0.1:5000/process',\n",
    "            json={'paragraph': text_to_process}\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            st.subheader(\"Extractive Summary:\")\n",
    "            st.write(result.get('summary'))\n",
    "        else:\n",
    "            st.error(f\"Error: {response.json().get('error')}\")\n",
    "\n",
    "        abstractive_text = \"This is the abstractive summary based on the input text.\"\n",
    "\n",
    "        st.subheader(\"Abstractive Text\")\n",
    "        st.write(abstractive_text)\n",
    "    else:\n",
    "        st.error(\"Please enter some text before processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8d46f3b1ddc9035f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T08:16:46.038417Z",
     "start_time": "2024-08-03T08:16:46.033595Z"
    }
   },
   "outputs": [],
   "source": [
    "# !streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183139a02a7a68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
