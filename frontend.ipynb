{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-15T19:55:34.313286Z",
     "start_time": "2024-08-15T19:55:34.279496Z"
    }
   },
   "source": [
    "%%writefile app.py\n",
    "import heapq\n",
    "import re\n",
    "from io import BytesIO\n",
    "\n",
    "import PyPDF2\n",
    "import streamlit as st\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load the extractive model\n",
    "@st.cache_resource\n",
    "def load_extractive_model():\n",
    "    try:\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        print(\"Model loaded successfully!\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "\n",
    "\n",
    "# load the abstractive model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "extractive_model = load_extractive_model()\n",
    "\n",
    "abstractive_model, abstractive_tokenizer = load_model()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "abstractive_model = abstractive_model.to(device)\n",
    "\n",
    "\n",
    "def generate_abstractive_summary(text):\n",
    "    max_summary_length = max(30, min(len(text.split()) // 2, 150))\n",
    "\n",
    "    inputs = abstractive_tokenizer(text, max_length=1024, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    summary_ids = abstractive_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        num_beams=4,\n",
    "        max_length=max_summary_length,\n",
    "        min_length=30,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = abstractive_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(len(summary))\n",
    "    return summary\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    # remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove \\n and quotes like “, ‘, ”\n",
    "    text = re.sub(r'[\\n“”‘’]', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    embeddings = extractive_model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def generate_extractive_summary(text, summary_ratio=0.3):\n",
    "    text = clean_text(text)\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    # Compute sentence embeddings\n",
    "    sentence_embeddings = compute_sentence_embeddings(sentences)\n",
    "\n",
    "    # Compute pairwise sentence similarities\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_score = util.pytorch_cos_sim(sentence_embeddings[i], sentence_embeddings).sum().item()\n",
    "        sentence_scores[sentence] = sentence_score / len(sentences)  # Normalize by number of sentences\n",
    "\n",
    "    # Get the top `summary_ratio`% of sentences with the highest scores\n",
    "    num_summary_sentences = max(1, int(len(sentences) * summary_ratio))\n",
    "    summary_sentences = heapq.nlargest(num_summary_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    pdf_reader = PyPDF2.PdfReader(BytesIO(pdf_file.read()))\n",
    "    c = 0\n",
    "    text = \"\"\n",
    "\n",
    "    while c < len(pdf_reader.pages):\n",
    "        pageObj = pdf_reader.pages[c]\n",
    "        page_text = pageObj.extract_text()\n",
    "        if page_text:\n",
    "            # Add line breaks based on common patterns\n",
    "            page_text = re.sub(r'\\n+', '\\n', page_text)\n",
    "            text += page_text + \"\\n\"\n",
    "        c += 1\n",
    "\n",
    "    return text.replace('\\n', ' ')\n",
    "\n",
    "\n",
    "# Title of the app\n",
    "st.title(\"Text Summarization App\")\n",
    "\n",
    "# Option to upload PDF or enter text\n",
    "option = st.radio(\"Choose input method\", [\"Upload PDF\", \"Enter Text\"])\n",
    "\n",
    "text_to_process = \"\"\n",
    "\n",
    "# Handle PDF upload\n",
    "if option == \"Upload PDF\":\n",
    "    uploaded_file = st.file_uploader(\"Choose a PDF file\", type=\"pdf\")\n",
    "    if uploaded_file is not None:\n",
    "        # Extract text from PDF\n",
    "        pdf_text = extract_text_from_pdf(uploaded_file)\n",
    "        st.text_area(\"Extracted Text\", pdf_text, height=130, )\n",
    "        text_to_process = pdf_text\n",
    "    else:\n",
    "        text_to_process = \"\"\n",
    "\n",
    "# Handle direct text input\n",
    "elif option == \"Enter Text\":\n",
    "    text_to_process = st.text_area(\"Enter your paragraph to summarize here:\", height=120)\n",
    "\n",
    "# Button to process the text\n",
    "if st.button(\"Generate Summary\"):\n",
    "    if text_to_process:\n",
    "        with st.spinner(\"Generating summary...\"):\n",
    "            # extractive_summary = generate_extractive_summary(text_to_process)\n",
    "            try:\n",
    "                extractive_summary = generate_extractive_summary(text_to_process)\n",
    "            except Exception as e:\n",
    "                st.error(f\"An error occurred: {e}\")\n",
    "                extractive_summary = None\n",
    "            try:\n",
    "                abstractive_summary = generate_abstractive_summary(text_to_process)\n",
    "            except Exception as e:\n",
    "                st.error(f\"An error occurred: {e}\")\n",
    "                abstractive_summary = None\n",
    "\n",
    "        # try:\n",
    "        #     extractive_summary = generate_extractive_summary(text_to_process)\n",
    "        # except Exception as e:\n",
    "        #     st.error(f\"An error occurred: {e}\")\n",
    "        #     extractive_summary = None\n",
    "\n",
    "        if extractive_summary:\n",
    "            st.subheader(\"Extractive Summary:\")\n",
    "            st.write(extractive_summary)\n",
    "        else:\n",
    "            st.error(f\"Error: while getting the extractive summary.\")\n",
    "\n",
    "        # try:\n",
    "        #     abstractive_summary = generate_abstractive_summary(text_to_process)\n",
    "        # except Exception as e:\n",
    "        #     st.error(f\"An error occurred: {e}\")\n",
    "        #     abstractive_summary = None\n",
    "\n",
    "        if abstractive_summary:\n",
    "            st.subheader(\"Abstractive Summary:\")\n",
    "            st.write(abstractive_summary)\n",
    "        else:\n",
    "            st.error(f\"Error: while getting the abstractive summary.\")\n",
    "    else:\n",
    "        st.error(\"Please enter some text before processing.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "70ad3eb6b2fd48e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
